#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MoziBang æ¿€æ´»ç ç³»ç»Ÿç»Ÿè®¡æŠ¥è¡¨æ¨¡å—
æä¾›è¯¦ç»†çš„æ¿€æ´»ç ä½¿ç”¨ç»Ÿè®¡å’ŒæŠ¥è¡¨åŠŸèƒ½
"""

import sqlite3
import pymysql
import json
import datetime
from collections import defaultdict
import os

# æ•°æ®åº“è·¯å¾„
DB_PATH = os.path.join(os.path.dirname(__file__), 'mozibang_activation.db')

def get_db_connection():
    """èŽ·å–æ•°æ®åº“è¿žæŽ¥"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

class ActivationStatistics:
    """æ¿€æ´»ç ç»Ÿè®¡ç±»"""
    
    def __init__(self, db_connection=None):
        """åˆå§‹åŒ–ç»Ÿè®¡ç±»ï¼Œæ”¯æŒä¼ å…¥å¤–éƒ¨æ•°æ®åº“è¿žæŽ¥"""
        if db_connection:
            self.conn = db_connection
            self.is_mysql = True
        else:
            self.conn = get_db_connection()
            self.is_mysql = False
    
    def __del__(self):
        # å¦‚æžœæ˜¯å¤–éƒ¨ä¼ å…¥çš„è¿žæŽ¥ï¼Œä¸è¦å…³é—­å®ƒ
        if hasattr(self, 'conn') and not self.is_mysql:
            self.conn.close()
    
    def get_activation_overview(self):
        """èŽ·å–æ¿€æ´»ç æ€»è§ˆç»Ÿè®¡"""
        cursor = self.conn.cursor()
        
        # æ¿€æ´»ç æ€»ä½“ç»Ÿè®¡
        cursor.execute("""
            SELECT 
                code_type,
                COUNT(*) as total_codes,
                SUM(CASE WHEN is_used = 1 THEN 1 ELSE 0 END) as used_codes,
                SUM(CASE WHEN is_used = 0 AND is_disabled = 0 THEN 1 ELSE 0 END) as available_codes,
                SUM(CASE WHEN is_disabled = 1 THEN 1 ELSE 0 END) as disabled_codes
            FROM activation_codes 
            GROUP BY code_type
            ORDER BY code_type
        """)
        
        code_stats = []
        for row in cursor.fetchall():
            code_stats.append({
                'code_type': row['code_type'],
                'total_codes': row['total_codes'],
                'used_codes': row['used_codes'],
                'available_codes': row['available_codes'],
                'disabled_codes': row['disabled_codes'],
                'usage_rate': round((row['used_codes'] / row['total_codes']) * 100, 2) if row['total_codes'] > 0 else 0
            })
        
        return code_stats
    
    def get_user_statistics(self):
        """èŽ·å–ç”¨æˆ·ç»Ÿè®¡"""
        cursor = self.conn.cursor()
        
        # Proç”¨æˆ·ç»Ÿè®¡
        cursor.execute("""
            SELECT 
                pro_type,
                COUNT(*) as total_users,
                SUM(CASE WHEN is_active = 1 THEN 1 ELSE 0 END) as active_users,
                SUM(CASE WHEN is_active = 0 THEN 1 ELSE 0 END) as inactive_users,
                SUM(CASE WHEN expires_at IS NULL THEN 1 ELSE 0 END) as lifetime_users,
                SUM(CASE WHEN expires_at IS NOT NULL AND expires_at > datetime('now') THEN 1 ELSE 0 END) as valid_users,
                SUM(CASE WHEN expires_at IS NOT NULL AND expires_at <= datetime('now') THEN 1 ELSE 0 END) as expired_users
            FROM pro_users 
            GROUP BY pro_type
            ORDER BY pro_type
        """)
        
        user_stats = []
        for row in cursor.fetchall():
            user_stats.append({
                'pro_type': row['pro_type'],
                'total_users': row['total_users'],
                'active_users': row['active_users'],
                'inactive_users': row['inactive_users'],
                'lifetime_users': row['lifetime_users'],
                'valid_users': row['valid_users'],
                'expired_users': row['expired_users']
            })
        
        return user_stats
    
    def get_daily_activation_trend(self, days=30):
        """èŽ·å–æ¯æ—¥æ¿€æ´»è¶‹åŠ¿ï¼ˆæœ€è¿‘Nå¤©ï¼‰"""
        cursor = self.conn.cursor()
        
        if self.is_mysql:
            # MySQLè¯­æ³•
            cursor.execute("""
                SELECT 
                    DATE(activated_at) as activation_date,
                    COUNT(*) as activation_count,
                    COUNT(DISTINCT user_email) as unique_users
                FROM pro_users 
                WHERE activated_at >= DATE_SUB(NOW(), INTERVAL %s DAY)
                GROUP BY DATE(activated_at)
                ORDER BY activation_date DESC
            """, (days,))
        else:
            # SQLiteè¯­æ³•
            cursor.execute("""
                SELECT 
                    DATE(activated_at) as activation_date,
                    COUNT(*) as activation_count,
                    COUNT(DISTINCT user_email) as unique_users
                FROM pro_users 
                WHERE activated_at >= datetime('now', '-{} days')
                GROUP BY DATE(activated_at)
                ORDER BY activation_date DESC
            """.format(days))
        
        trend_data = []
        for row in cursor.fetchall():
            if self.is_mysql:
                trend_data.append({
                    'date': str(row['activation_date']),
                    'activations': row['activation_count'],
                    'unique_users': row['unique_users']
                })
            else:
                trend_data.append({
                    'date': row['activation_date'],
                    'activations': row['activation_count'],
                    'unique_users': row['unique_users']
                })
        
        return trend_data
    
    def get_code_type_distribution(self):
        """èŽ·å–æ¿€æ´»ç ç±»åž‹åˆ†å¸ƒ"""
        cursor = self.conn.cursor()
        
        cursor.execute("""
            SELECT 
                ac.code_type,
                COUNT(pu.id) as activated_count,
                AVG(CASE 
                    WHEN pu.expires_at IS NULL THEN NULL 
                    ELSE (julianday(pu.expires_at) - julianday(pu.activated_at))
                END) as avg_duration_days
            FROM activation_codes ac
            LEFT JOIN pro_users pu ON ac.code = pu.activation_code
            WHERE ac.is_used = 1
            GROUP BY ac.code_type
            ORDER BY activated_count DESC
        """)
        
        distribution = []
        for row in cursor.fetchall():
            distribution.append({
                'code_type': row['code_type'],
                'activated_count': row['activated_count'],
                'avg_duration_days': round(row['avg_duration_days'], 1) if row['avg_duration_days'] else None
            })
        
        return distribution
    
    def get_user_activity_report(self):
        """èŽ·å–ç”¨æˆ·æ´»åŠ¨æŠ¥å‘Š"""
        cursor = self.conn.cursor()
        
        # æœ€è¿‘æ¿€æ´»çš„ç”¨æˆ·
        cursor.execute("""
            SELECT 
                user_email,
                user_name,
                pro_type,
                activation_code,
                activated_at,
                expires_at,
                is_active,
                last_login
            FROM pro_users 
            ORDER BY activated_at DESC 
            LIMIT 20
        """)
        
        recent_activations = []
        for row in cursor.fetchall():
            recent_activations.append({
                'user_email': row['user_email'],
                'user_name': row['user_name'],
                'pro_type': row['pro_type'],
                'activation_code': row['activation_code'],
                'activated_at': row['activated_at'],
                'expires_at': row['expires_at'],
                'is_active': bool(row['is_active']),
                'last_login': row['last_login']
            })
        
        # å³å°†è¿‡æœŸçš„ç”¨æˆ·
        cursor.execute("""
            SELECT 
                user_email,
                user_name,
                pro_type,
                expires_at,
                (julianday(expires_at) - julianday('now')) as days_until_expiry
            FROM pro_users 
            WHERE expires_at IS NOT NULL 
            AND expires_at > datetime('now')
            AND expires_at <= datetime('now', '+30 days')
            ORDER BY expires_at ASC
        """)
        
        expiring_soon = []
        for row in cursor.fetchall():
            expiring_soon.append({
                'user_email': row['user_email'],
                'user_name': row['user_name'],
                'pro_type': row['pro_type'],
                'expires_at': row['expires_at'],
                'days_until_expiry': int(row['days_until_expiry'])
            })
        
        return {
            'recent_activations': recent_activations,
            'expiring_soon': expiring_soon
        }
    
    def get_revenue_estimation(self):
        """èŽ·å–æ”¶å…¥ä¼°ç®—ï¼ˆåŸºäºŽæ¿€æ´»ç ç±»åž‹ï¼‰"""
        # å‡è®¾çš„ä»·æ ¼æ˜ å°„
        price_mapping = {
            'pro_lifetime': 299.0,
            'pro_1year': 99.0,
            'pro_6month': 59.0
        }
        
        cursor = self.conn.cursor()
        
        cursor.execute("""
            SELECT 
                ac.code_type,
                COUNT(pu.id) as activated_count
            FROM activation_codes ac
            LEFT JOIN pro_users pu ON ac.code = pu.activation_code
            WHERE ac.is_used = 1
            GROUP BY ac.code_type
        """)
        
        revenue_data = []
        total_revenue = 0
        
        for row in cursor.fetchall():
            code_type = row['code_type']
            count = row['activated_count']
            price = price_mapping.get(code_type, 0)
            revenue = count * price
            total_revenue += revenue
            
            revenue_data.append({
                'code_type': code_type,
                'activated_count': count,
                'unit_price': price,
                'total_revenue': revenue
            })
        
        return {
            'revenue_by_type': revenue_data,
            'total_estimated_revenue': total_revenue
        }
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        report = {
            'generated_at': datetime.datetime.now().isoformat(),
            'activation_overview': self.get_activation_overview(),
            'user_statistics': self.get_user_statistics(),
            'daily_trend': self.get_daily_activation_trend(30),
            'code_distribution': self.get_code_type_distribution(),
            'user_activity': self.get_user_activity_report(),
            'revenue_estimation': self.get_revenue_estimation()
        }
        
        return report
    
    def export_report_to_json(self, filename=None):
        """å¯¼å‡ºæŠ¥å‘Šä¸ºJSONæ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'activation_report_{timestamp}.json'
        
        report = self.generate_comprehensive_report()
        
        filepath = os.path.join(os.path.dirname(__file__), filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        return filepath

def main():
    """ä¸»å‡½æ•° - ç”Ÿæˆç¤ºä¾‹æŠ¥å‘Š"""
    print("ðŸ“Š MoziBang æ¿€æ´»ç ç³»ç»Ÿç»Ÿè®¡æŠ¥å‘Š")
    print("=" * 50)
    
    stats = ActivationStatistics()
    
    # æ¿€æ´»ç æ€»è§ˆ
    print("\nðŸŽ« æ¿€æ´»ç æ€»è§ˆ:")
    overview = stats.get_activation_overview()
    for item in overview:
        print(f"  {item['code_type']}: æ€»è®¡{item['total_codes']}, å·²ç”¨{item['used_codes']}, å¯ç”¨{item['available_codes']}, ä½¿ç”¨çŽ‡{item['usage_rate']}%")
    
    # ç”¨æˆ·ç»Ÿè®¡
    print("\nðŸ‘¥ ç”¨æˆ·ç»Ÿè®¡:")
    user_stats = stats.get_user_statistics()
    for item in user_stats:
        print(f"  {item['pro_type']}: æ€»è®¡{item['total_users']}, æ´»è·ƒ{item['active_users']}, æ°¸ä¹…{item['lifetime_users']}")
    
    # æ¯æ—¥è¶‹åŠ¿
    print("\nðŸ“ˆ æœ€è¿‘7å¤©æ¿€æ´»è¶‹åŠ¿:")
    trend = stats.get_daily_activation_trend(7)
    for item in trend[:7]:
        print(f"  {item['date']}: {item['activations']}æ¬¡æ¿€æ´», {item['unique_users']}ä¸ªç”¨æˆ·")
    
    # æ”¶å…¥ä¼°ç®—
    print("\nðŸ’° æ”¶å…¥ä¼°ç®—:")
    revenue = stats.get_revenue_estimation()
    for item in revenue['revenue_by_type']:
        print(f"  {item['code_type']}: {item['activated_count']}ä¸ª Ã— Â¥{item['unit_price']} = Â¥{item['total_revenue']}")
    print(f"  æ€»è®¡ä¼°ç®—æ”¶å…¥: Â¥{revenue['total_estimated_revenue']}")
    
    # å¯¼å‡ºå®Œæ•´æŠ¥å‘Š
    print("\nðŸ“„ å¯¼å‡ºå®Œæ•´æŠ¥å‘Š...")
    filepath = stats.export_report_to_json()
    print(f"âœ… æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filepath}")

if __name__ == '__main__':
    main()